{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(), 'data/robocall.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess Time of Issue to consistent format\n",
    "\n",
    "def preprocessTime(s):\n",
    "    if isinstance(s, float):\n",
    "        return s\n",
    "    s = re.sub(r'[^a-zA-Z\\d:]', '', s.lower())\n",
    "    condition = re.sub(r'[^:]*:[^\\D]*', '', s)\n",
    "    if 2 != len(condition):\n",
    "        if 'a' in condition:\n",
    "            s = re.match(r'[^:]*:[^\\D]*', s).group(0)+'am'\n",
    "        else:\n",
    "            s = re.match(r'[^:]*:[^\\D]*', s).group(0)+'pm'\n",
    "    return s\n",
    "\n",
    "df['Time of Issue'] = df['Time of Issue'].apply(preprocessTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropped all row entries with no provided location...\n",
    "## Asserts dropped data is insignificant information loss (assumed threshold 5%)\n",
    "\n",
    "assert len(df[df['Location (Center point of the Zip Code)'].isnull()])/len(df) < 0.05\n",
    "df = df.dropna(subset = ['Location (Center point of the Zip Code)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Location dictionary with (zip code, location coordinate) pairs\n",
    "## Assumes df contains column 'Location (Center point of the Zip Code)'\n",
    "\n",
    "def getLocations(df, d = dict()):\n",
    "    splitter = lambda x: tuple(x.split('\\n'))\n",
    "    for entry in set(df['Location (Center point of the Zip Code)'].apply(splitter)):\n",
    "        if len(entry) == 2:\n",
    "            k, v = entry\n",
    "            d[k.split('-')[0].split(' ')[1]] = literal_eval(v)\n",
    "    return d\n",
    "\n",
    "locationDict = getLocations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts coordinates to respective timezone from UTC in seconds\n",
    "## Takes about ten minutes if timeZoneDict.pickle doesn't exist\n",
    "\n",
    "if not os.path.isfile(\"timeZoneDict.pickle\"):\n",
    "    ## Requires timezonefinder (if we deploy to application, we'll add this to requirements.txt)\n",
    "    ! pip install timezonefinder\n",
    "    from timezonefinder import TimezoneFinder\n",
    "    from pytz import timezone\n",
    "    import pytz\n",
    "    \n",
    "    tf = TimezoneFinder()\n",
    "    utc = pytz.utc\n",
    "\n",
    "    def offset(coordinates):\n",
    "        latitude, longitude = coordinates\n",
    "        target = dict({'lat':latitude, 'lng':longitude})\n",
    "        today = datetime.now()\n",
    "        tz_target = timezone(tf.certain_timezone_at(lat=target['lat'], lng=target['lng']))\n",
    "        today_target = tz_target.localize(today)\n",
    "        today_utc = utc.localize(today)\n",
    "        return (today_utc - today_target).total_seconds()\n",
    "\n",
    "    timeZoneDict = {k: offset(v) for k, v in locationDict.items()}\n",
    "    serialized = open(\"timeZoneDict.pickle\", \"wb\")\n",
    "    pickle.dump(timeZoneDict, serialized)\n",
    "    serialized.close()\n",
    "else:\n",
    "    deserialized = open(\"timeZoneDict.pickle\",\"rb\")\n",
    "    timeZoneDict = pickle.load(deserialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts coordinates to area code\n",
    "## Takes about ten minutes if areaCodeDict.pickle doesn't exist\n",
    "\n",
    "if not os.path.isfile(\"areaCodeDict.pickle\"):\n",
    "    def geocoordinateDistance(origin, destination):\n",
    "        #Computes distance between 2 geo coordinate points\n",
    "        #Taken from https://gist.github.com/rochacbruno/2883505\n",
    "        #Author: Wayne Dyck\n",
    "        from math import radians, sin, cos, atan2, sqrt\n",
    "        lat1, lon1 = origin\n",
    "        lat2, lon2 = destination\n",
    "        radius = 6371 # km\n",
    "\n",
    "        dlat = radians(lat2-lat1)\n",
    "        dlon = radians(lon2-lon1)\n",
    "        a = sin(dlat/2) * sin(dlat/2) + cos(radians(lat1)) \\\n",
    "            * cos(radians(lat2)) * sin(dlon/2) * sin(dlon/2)\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "        d = radius * c\n",
    "\n",
    "        return d\n",
    "\n",
    "    def findAreaCode(coordinates):\n",
    "        areaCode = pd.read_csv(os.path.join(os.getcwd(),\n",
    "            'data/area-code-to-lat-long.csv'))\n",
    "        areaCode['Loc'] = list(zip(areaCode.Lat, areaCode.Long))\n",
    "        areaCode['Distance'] = areaCode['Loc'].apply(lambda x:\n",
    "            geocoordinateDistance(x, coordinates))\n",
    "        return areaCode.iloc[areaCode['Distance'].idxmin()]['Area Code']\n",
    "\n",
    "    areaCodeDict = {k: findAreaCode(v) for k,v in locationDict.items()}\n",
    "    serialized2 = open(\"areaCodeDict.pickle\", \"wb\")\n",
    "    pickle.dump(areaCodeDict, serialized2)\n",
    "    serialized2.close()\n",
    "else:\n",
    "    deserialized2 = open(\"areaCodeDict.pickle\",\"rb\")\n",
    "    areaCodeDict = pickle.load(deserialized2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"areaCodeToLatLongPickle.pickle\"):\n",
    "    areaCodeToLocation = {}\n",
    "    with open('data/area-code-to-lat-long.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            [area_code, lat, _long] = row\n",
    "            areaCodeToLocation[area_code] = (float(lat), float(_long))\n",
    "        f.close()\n",
    "\n",
    "    with open(\"areaCodeToLatLongPickle\", \"wb+\") as f:\n",
    "        pickle.dump(areaCodeToLocation, f)\n",
    "        f.close()\n",
    "else:\n",
    "    deserialized2 = open(\"areaCodeToLatLongPickle.pickle\",\"rb\")\n",
    "    areaCodeToLocation = pickle.load(deserialized2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess Location and Zip to consistent format\n",
    "## Converts Ticket Created to datetime object in df master dataframe\n",
    "## Fill some NaN phone numbers so that 'Caller ID Number' accepts defined entry in 'Advertiser Number'\n",
    "## Remove 'Accessibility', 'Emergency', 'Request for Dispute Assistance' forms (incomplete data)\n",
    "\n",
    "def preprocessLocation(s):\n",
    "    s = re.sub(r'(\\d)\\(', r'\\1\\n(', s)\n",
    "    return s.split('\\n')[0].split(' ')[-1].split('-')[0]\n",
    "\n",
    "def location(zipCode):\n",
    "    try:\n",
    "        return locationDict[zipCode]\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "def convertAreaCode(areaCode):\n",
    "    try:\n",
    "        return areaCodeToLocation[areaCode]\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "df = df.rename(index = str, columns = {'Location (Center point of the Zip Code)': 'Location (Target)'})\n",
    "df['Zip'] = df['Location (Target)'].apply(preprocessLocation)\n",
    "df['Location (Target)'] = df['Location (Target)'].apply(lambda x: location(preprocessLocation(x)))\n",
    "df = df.dropna(subset = ['Location (Target)'])\n",
    "df['Ticket Created'] = df['Ticket Created'].apply(lambda x: datetime.strptime(x[:-6], \"%m/%d/%Y %I:%M:%S %p\"))\n",
    "\n",
    "subset = df[['Caller ID Number', 'Advertiser Business Number']].fillna('')\n",
    "df['Caller ID Number'] = subset['Caller ID Number'].combine(\n",
    "    subset['Advertiser Business Number'], max).replace('', np.nan, regex=True)\n",
    "\n",
    "insignificant = ['Accessibility', 'Emergency', 'Request for Dispute Assistance']\n",
    "assert df[df.Form.isin(insignificant)].groupby('Form')['Ticket ID'].nunique().sum()/len(df) < 0.05\n",
    "df = df[~df.Form.isin(insignificant)]\n",
    "\n",
    "df['Area Code (Target)'] = df['Zip'].apply(lambda x: areaCodeDict[x])\n",
    "df['Area Code (Source)'] = df['Caller ID Number'].apply(lambda x: x.split('-')[0] if isinstance(x, str) else x).replace('None', np.nan)\n",
    "\n",
    "## Removes Internet data given lack of available information per feature\n",
    "df = df[~(df.Form == 'Internet')]\n",
    "\n",
    "## Adds location coordinates for source of spam call\n",
    "df['Location (Source)'] = df['Area Code (Source)'].apply(convertAreaCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column Type of Call or Messge under form TV contains 0.0% defined row entries.\n",
      "The column Area Code (Source) under form TV contains 0.0% defined row entries.\n",
      "The column Location (Source) under form TV contains 0.0% defined row entries.\n",
      "The column Type of Call or Messge under form Radio contains 0.0% defined row entries.\n",
      "The column Area Code (Source) under form Radio contains 0.0% defined row entries.\n",
      "The column Location (Source) under form Radio contains 0.0% defined row entries.\n"
     ]
    }
   ],
   "source": [
    "## Some columns with predominately null values under given form. Should be noted.\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def computePercentageOfNull(form, columnName, data = df):\n",
    "    return len(data[data.Form == form][columnName].dropna())/len(data[data.Form == form][columnName])\n",
    "\n",
    "for form, column in product(set(df.Form), df.columns):\n",
    "    percentage = computePercentageOfNull(form, column)\n",
    "    if percentage < 0.05:\n",
    "        print('The column {} under form {} contains {}% defined row entries.'.format(column, form, 100*percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "## Assumes 80-20 train-test split under seed value 8888 for reproducability of results\n",
    "## Creates Issue DateTime column in data and fixes misrecorded dates of issue\n",
    "## Assumes all reports are submitted within a day of receiving spam call\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def convert(x):\n",
    "    return x['Issue DateTime'] - timedelta(seconds = x['Offset'])  \n",
    "\n",
    "def computeTimeDifference(row):\n",
    "    try:\n",
    "        return row[\"Ticket Created\"] - row[\"Issue DateTime UTC\"] \n",
    "    except ValueError as e:\n",
    "        if \"Out of bounds nanosecond timestamp:\" in str(e):\n",
    "            return np.nan\n",
    "\n",
    "data = df.dropna(subset = ['Date of Issue', 'Time of Issue'])\n",
    "data[\"Issue DateTime\"] = (data[\"Date of Issue\"] + ' ' + data[\"Time of Issue\"]).apply(\n",
    "    lambda x: datetime.strptime(x, \"%m/%d/%Y %I:%M%p\"))\n",
    "data['Offset'] = data['Zip'].apply(lambda x: timeZoneDict[x])\n",
    "data['Issue DateTime UTC'] = data[['Issue DateTime', 'Offset']].apply(convert, axis = 1)\n",
    "\n",
    "columns = [\"Ticket ID\", \"Ticket Created\", \"Issue DateTime UTC\"]\n",
    "data['Time Elapsed'] = data[columns].apply(computeTimeDifference, axis = 1)\n",
    "\n",
    "data['Issue DateTime UTC'] = data['Ticket Created'] - (data['Time Elapsed'] - \n",
    "    pd.to_timedelta(data['Time Elapsed'].dt.days, unit='d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized3 = open(\"df.pickle\", \"wb\")\n",
    "pickle.dump(df, serialized3)\n",
    "serialized3.close()\n",
    "\n",
    "serialized4 = open(\"modeldf.pickle\", \"wb\")\n",
    "pickle.dump(data, serialized4)\n",
    "serialized4.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
